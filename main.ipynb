{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIB :** https://donnees.banquemondiale.org/indicateur/NY.GDP.MKTP.CD  \n",
    "**Taux de chômage :**  \n",
    "**Taux d'intérêts des dépôts :** https://donnees.banquemondiale.org/indicateur/FR.INR.DPST?most_recent_value_desc=false&view=chart  \n",
    "**IPCH :**  \n",
    "**Historique des actions :**  \n",
    "**Devise:** https://ec.europa.eu/eurostat/databrowser/view/tec00033/default/table?lang=en&category=t_ert  \n",
    "**Matières premières:** https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/010002100 **et** https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/010002091  \n",
    "**Dette publique:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type d'analyses prévus et résultats attendus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses prévues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Corrélations entre les différentes données  \n",
    "- Etude d'indices boursiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats attendus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIB\n",
    "Un PIB croissant est souvent associé à une économie forte, ce qui peut influencer positivement les marchés boursiers. L'analyse cherchera à quantifier cette relation.  \n",
    "\n",
    "### Taux de chômage\n",
    "Un faible taux de chômage peut refléter une économie robuste et un climat favorable aux entreprises, impactant ainsi les actions. Les corrélations entre ces données et les performances boursières seront examinées.  \n",
    "\n",
    "### Taux d'intérêts des dépôts\n",
    "Les variations des taux d'intérêt influencent directement l'attractivité des investissements en actions. Une corrélation négative est souvent attendue entre les taux d'intérêt et les performances des marchés.  \n",
    "\n",
    "### IPCH (Indice des Prix à la Consommation Harmonisé)\n",
    "L'inflation, mesurée ici par l'IPCH, est un facteur clé pour comprendre les ajustements des marchés financiers aux variations des taux d'intérêt et des prix.  \n",
    "\n",
    "### Historique des actions\n",
    "L'analyse des tendances passées dans les cours des actions permettra d'évaluer la réactivité des marchés aux changements des indicateurs économiques.  \n",
    "\n",
    "### Devise\n",
    "Les fluctuations des taux de change peuvent avoir un impact direct, notamment pour les entreprises opérant à l'international. Les relations entre les cours des actions et les variations des devises seront explorées.  \n",
    "\n",
    "### Matières premières\n",
    "Certains secteurs boursiers sont fortement dépendants des prix des matières premières. L'étude analysera les corrélations spécifiques entre ces prix et les performances des actions dans les secteurs concernés.  \n",
    "\n",
    "### Dette intérieure\n",
    "Le niveau d'endettement d'un pays peut influencer la confiance des investisseurs et, par conséquent, le comportement des marchés. L'étude des corrélations dans ce contexte sera essentielle.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Début du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "\n",
    "import ipywidgets as  widgets\n",
    "from ipywidgets import interact, widgets, VBox, HBox\n",
    "from ipywidgets import interact_manual\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dette publique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the Excel file\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "# Importer les données depuis l'URL\n",
    "dette_publique_url = 'https://sebastien-hein.emi.u-bordeaux.fr/OI-sbzrthstrm/DATA/dette_pub.xlsx'\n",
    "code_url = 'https://sebastien-hein.emi.u-bordeaux.fr/OI-sbzrthstrm/DATA/code.tsv'\n",
    "\n",
    "# Charger les fichiers directement depuis l'URL\n",
    "dette_publique = pd.read_excel(dette_publique_url, sheet_name='Feuille 1')\n",
    "code = pd.read_csv(code_url, sep='\\t')\n",
    "\n",
    "# Define column names for code and label\n",
    "col_code = 'CODE'\n",
    "col_label = 'Label - French'\n",
    "\n",
    "def find_value(x):\n",
    "    \"\"\"Find the label value based on the code.\"\"\"\n",
    "    matched = not code[code[col_code] == x].empty\n",
    "    if matched:\n",
    "        return code[code[col_code] == x].loc[:, col_label].iloc[0]\n",
    "    elif x == 'TIME':\n",
    "        return 'Country'\n",
    "    return None\n",
    "\n",
    "# Modify the index of the dataframe\n",
    "dette_publique.index = dette_publique.iloc[:, 0].apply(find_value)\n",
    "dette_publique.index.name = None\n",
    "\n",
    "# Set the column names based on the 'Country' row\n",
    "dette_publique.columns = dette_publique.loc['Country']\n",
    "\n",
    "# Filter the dataframe to include only rows from 'Belgique' to 'Suède' onwards and exclude the 'TIME' column\n",
    "# Indeed, only the countries interest us,\n",
    "# and the datas are missing for Islande, Norvège, Suisse and United Kingdom.\n",
    "dette_publique = dette_publique.loc['Belgique':'Suède', dette_publique.columns != 'TIME']\n",
    "\n",
    "# Filter the dataframe to include only columns from the year 2002 onwards\n",
    "dette_publique = dette_publique.loc[:,2002:] # Problème non résolu: Si l'on prend une date inférieure à 2002, \n",
    "                                             #                      l'interpolation ne fonctionne nul part.\n",
    "\n",
    "def to_date(x):\n",
    "    \"\"\"Convert a value to datetime.\"\"\"\n",
    "    return pd.to_datetime(x, format='%Y')\n",
    "\n",
    "# Vectorize the to_date function\n",
    "vect_to_date = np.vectorize(to_date)\n",
    "\n",
    "# Convert the columns to datetime\n",
    "dette_publique.columns = vect_to_date(dette_publique.columns.values)\n",
    "\n",
    "monthly_dates = pd.date_range(start=dette_publique.columns.values[0], end=dette_publique.columns.values[-1], freq='MS')\n",
    "\n",
    "# Add columns for each month from 2013 to 2023\n",
    "dette_publique = dette_publique.reindex(columns=dette_publique.columns.union(monthly_dates))\n",
    "\n",
    "def fill_val(x):\n",
    "    \"\"\"Fill missing values by resampling and interpolating.\"\"\"\n",
    "    return x.resample('MS').interpolate(method='quadratic')\n",
    "\n",
    "# Apply the fill_val function to each row\n",
    "dette_publique = dette_publique.apply(func=fill_val, axis=1).T\n",
    "dette_publique.columns.name = 'Country'\n",
    "\n",
    "dette_publique.isna().sum().sum() # Number of missing values (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albanie: [('2010-12', '2016-11')]\n",
      "Monténégro: [('2010-12', '2015-11')]\n",
      "United Kingdom: [('2020-12', '2024-11')]\n",
      "Kosovo*: [('2010-12', '2016-11')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define URLs for the data sources\n",
    "ipch_url = 'https://sebastien-hein.emi.u-bordeaux.fr/OI-sbzrthstrm/DATA/ipch.tsv'\n",
    "code_cp_url = 'https://sebastien-hein.emi.u-bordeaux.fr/OI-sbzrthstrm/DATA/code_cp.tsv'\n",
    "\n",
    "# Load the data directly from the URLs\n",
    "ipch = pd.read_csv(ipch_url, sep='\\t')  # Load the ipch data using tab as a separator\n",
    "code_cp = pd.read_csv(code_cp_url, sep='\\t')  # Load the code_cp data using tab as a separator\n",
    "\n",
    "\n",
    "# Set index\n",
    "def get_CP(x): return x[8:12]  # Extract CP code\n",
    "def get_id(x): return x[13:]  # Extract id\n",
    "vect_get_cp = np.vectorize(get_CP)\n",
    "vect_get_id = np.vectorize(get_id)\n",
    "ipch['CP'] = vect_get_cp(ipch.iloc[:, 0])  # Apply CP extraction\n",
    "ipch['id'] = vect_get_id(ipch.iloc[:, 0])  # Apply id extraction\n",
    "\n",
    "ipch = ipch[ipch['CP'] == 'CP00']\n",
    "ipch.drop(columns = 'CP', inplace = True)\n",
    "\n",
    "ipch.drop(columns='freq,unit,coicop,geo\\\\TIME_PERIOD', inplace=True)  # Drop unnecessary columns\n",
    "ipch['country'] = ipch.loc[:, 'id'].apply(find_value)  # Find country names\n",
    "ipch.set_index(['country'], inplace=True)  # Set index\n",
    "ipch.drop(columns='id', inplace=True)  # Drop id column\n",
    "\n",
    "# Convert the columns to datetime\n",
    "def to_date_M(x):\n",
    "    \"\"\"Convert a value to datetime.\"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(x[:-1], format='%Y-%m')\n",
    "    except:\n",
    "        print('fail')\n",
    "        return x\n",
    "\n",
    "vect_to_date_M = np.vectorize(to_date_M)\n",
    "ipch.columns = vect_to_date_M(ipch.columns.values)  # Apply datetime conversion\n",
    "\n",
    "# Filter data\n",
    "ipch = ipch[~ipch.index.str.startswith(('Union', 'Zone', 'Espace'))]  # Exclude certain countries\n",
    "\n",
    "# Clean and convert to numeric\n",
    "ipch = ipch.map(lambda x: pd.to_numeric(\n",
    "    str(x).replace(' ', '').replace('d', ''), errors='coerce'))\n",
    "ipch = ipch.T\n",
    "ipch.columns.name = 'Country'\n",
    "\n",
    "# Missing values\n",
    "# Initialiser le dictionnaire pour stocker les plages de dates manquantes\n",
    "missing_ranges = defaultdict(list)\n",
    "\n",
    "# Identifier les valeurs manquantes\n",
    "missing_values = ipch.isna()\n",
    "\n",
    "# Parcourir chaque pays (colonne) pour trouver les plages de dates manquantes\n",
    "for country in ipch.columns:\n",
    "    country_missing = missing_values[country]\n",
    "    if not country_missing.empty:\n",
    "        # Trouver les plages de dates manquantes\n",
    "        missing_dates = country_missing[country_missing].index\n",
    "        start_date = None\n",
    "        for date in missing_dates:\n",
    "            if start_date is None:\n",
    "                start_date = date\n",
    "            if (date + pd.DateOffset(months=1)) not in missing_dates:\n",
    "                end_date = date\n",
    "                missing_ranges[country].append((start_date.strftime('%Y-%m'), end_date.strftime('%Y-%m')))\n",
    "                start_date = None\n",
    "\n",
    "# Convertir le defaultdict en dict\n",
    "missing_ranges = dict(missing_ranges)\n",
    "\n",
    "for country, dates in missing_ranges.items():\n",
    "    print(f'{country}: {dates}')\n",
    "\n",
    "# Delete the country for which the missing data is on a bigger period than 4 years\n",
    "ipch.drop(columns = 'Albanie, Kosovo*, Monténégro'.split(', '), inplace = True)\n",
    "\n",
    "# Fill missing values using interpolation as the most consistent method for long gaps\n",
    "ipch.interpolate(method='time', inplace=True, limit_direction='both')  # Interpolate linearly by date for smoother transitions\n",
    "\n",
    "# Optionally fill remaining missing values (if interpolation failed for some edge cases) with column mean\n",
    "ipch.fillna(ipch.mean(), inplace=True)\n",
    "\n",
    "ipch.isna().sum().sum() # Number of missing values (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chomage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_xml(file_url):\n",
    "    \"\"\"Parse XML file and extract data into a DataFrame.\"\"\"\n",
    "    \n",
    "    # Download the XML file content using requests\n",
    "    response = requests.get(file_url)\n",
    "    xml_content = response.text  # Get the content of the XML file as a string\n",
    "    \n",
    "    # Parse the XML content with ElementTree\n",
    "    root = ET.fromstring(xml_content)  # Parse the XML string directly\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    data = []\n",
    "    columns = set()\n",
    "    rows = set()\n",
    "\n",
    "    # Extract data from <Series> and <Obs> tags\n",
    "    for series in root.findall('.//Series'):\n",
    "        geo = series.attrib.get('geo')  # Get \"geo\" attribute\n",
    "        if geo:\n",
    "            rows.add(geo)\n",
    "            for obs in series.findall('Obs'):\n",
    "                time_period = obs.attrib.get('TIME_PERIOD')  # Get \"TIME_PERIOD\" attribute\n",
    "                obs_value = obs.attrib.get('OBS_VALUE')  # Get \"OBS_VALUE\" attribute\n",
    "                if time_period and obs_value:\n",
    "                    columns.add(time_period)\n",
    "                    data.append((geo, time_period, obs_value))\n",
    "\n",
    "    # Create DataFrame with appropriate indices\n",
    "    df = pd.DataFrame(index=sorted(rows), columns=sorted(columns))\n",
    "\n",
    "    # Fill DataFrame with extracted values\n",
    "    for geo, time_period, obs_value in data:\n",
    "        df.at[geo, time_period] = obs_value\n",
    "\n",
    "    return df\n",
    "\n",
    "# URL for the XML data\n",
    "file_url = 'https://sebastien-hein.emi.u-bordeaux.fr/OI-sbzrthstrm/DATA/chomage.xml'\n",
    "\n",
    "# Load the data\n",
    "chomage = parse_xml(file_url)\n",
    "\n",
    "# Format the data\n",
    "chomage.columns = chomage.columns.map(lambda x: \\\n",
    "                                      pd.to_datetime(x, format='%Y-%m'))  # Convert columns to datetime\n",
    "chomage.index = chomage.index.map(lambda x: \\\n",
    "                code.loc[code.loc[:, 'CODE'] == x, 'Label - French'].iloc[0])  # Map index to labels\n",
    "chomage.drop('Zone euro - 20 pays (à partir de 2023)', inplace=True)  # Drop specific rows\n",
    "chomage.drop('Union européenne - 27 pays (à partir de 2020)', inplace=True)  # Drop specific rows\n",
    "chomage = chomage.apply(pd.to_numeric).T  # Convert data to numeric\n",
    "chomage.columns.name = 'Country'\n",
    "\n",
    "\n",
    "# Missing values\n",
    "missing_ranges = defaultdict(list) # Initialiser le dictionnaire pour stocker les plages de dates manquantes\n",
    "missing_values = chomage.isna() # Identifier les valeurs manquantes\n",
    "\n",
    "for country in chomage.columns: # Parcourir chaque pays (colonne) pour trouver les plages de dates manquantes\n",
    "    country_missing = missing_values[country]\n",
    "    if country_missing.any():\n",
    "        # Trouver les plages de dates manquantes\n",
    "        missing_dates = country_missing[country_missing].index\n",
    "        start_date = None\n",
    "        for date in missing_dates:\n",
    "            if start_date is None:\n",
    "                start_date = date\n",
    "            if date + pd.DateOffset(months=1) not in missing_dates:\n",
    "                end_date = date\n",
    "                missing_ranges[country].append((start_date.strftime('%Y-%m'), \n",
    "                                                end_date.strftime('%Y-%m')))\n",
    "                start_date = None\n",
    "\n",
    "# Fill missing values using interpolation as the most consistent method for long gaps\n",
    "chomage.interpolate(method='time', inplace=True, limit_direction='both')  # Interpolate linearly by date for smoother transitions\n",
    "\n",
    "# Optionally fill remaining missing values (if interpolation failed for some edge cases) with column mean\n",
    "chomage.fillna(chomage.mean(), inplace=True)\n",
    "\n",
    "ipch.isna().sum().sum() # Number of missing values (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_pib(file_url):\n",
    "    \"\"\"Parse XML file and extract data into a DataFrame.\"\"\"\n",
    "    \n",
    "    # Download the XML file content using requests\n",
    "    response = requests.get(file_url)\n",
    "    xml_content = response.text  # Get the content of the XML file as a string\n",
    "    \n",
    "    # Parse the XML content with ElementTree\n",
    "    root = ET.fromstring(xml_content)  # Parse the XML string directly\n",
    "    \n",
    "    # Initialize a list to store data\n",
    "    data = []\n",
    "\n",
    "    # Extract data\n",
    "    for record in root.findall('.//record'):\n",
    "        record_data = {}\n",
    "        for field in record.findall('field'):\n",
    "            name = field.attrib.get('name')\n",
    "            text = field.text\n",
    "            match name:\n",
    "                case \"Country or Area\": record_data['country'] = text\n",
    "                case \"Value\": \n",
    "                    try: record_data['value'] = float(text)\n",
    "                    except: record_data['value'] = None\n",
    "                case \"Year\": record_data['year'] = pd.to_datetime(str(text))\n",
    "        data.append(record_data)\n",
    "\n",
    "    # Create DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['year', 'country'])\n",
    "\n",
    "    # Pivot the DataFrame to get the desired format\n",
    "    df = df.pivot(index='year', columns='country', values='value')\n",
    "\n",
    "    return df\n",
    "\n",
    "url = 'https://julie-sclaunich.emi.u-bordeaux.fr/DATA/API_NY.GDP.MKTP.CD_DS2_fr_xml_v2_38351.xml'\n",
    "pib = parse_xml_pib(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reindex monthly\n",
    "monthly_dates = pd.date_range(start=pib.index.values[0], end=pib.index.values[-1], freq='MS')\n",
    "\n",
    "# Add columns for each month from 2013 to 2023\n",
    "pib = pib.reindex(index=pib.index.union(monthly_dates))\n",
    "pib.columns.name = 'Country'\n",
    "\n",
    "# Select only same dates and countries as dette_publique\n",
    "pib = pib.loc[dette_publique.index, dette_publique.columns.intersection(pib.columns)]\n",
    "\n",
    "def fill_val(x):\n",
    "    \"\"\"Fill missing values by resampling and interpolating.\"\"\"\n",
    "    return x.resample('MS').interpolate(method='quadratic')\n",
    "\n",
    "# Apply the fill_val function to each row\n",
    "pib = pib.apply(func=fill_val, axis=0)\n",
    "\n",
    "pib.isna().sum().sum() # Number of missing values (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taux d'intérêt\n",
    "\n",
    "A priori, que des NA pour les pays d'Europe ?\\\n",
    "Décommenter le code `# taux = taux.loc[dette_publique.index, dette_publique.columns.intersection(taux.columns)]` vide complètement la df. Il s'agit de faire l'intersection entre les colonnes de (donc les pays présents dans) dette_publique avec celles de taux. J'imagine que si le résultat est vide, c'est que pour tous les pays de dette_publique ont des valeurs NA dans taux.\\\n",
    "Peut-être que c'est logique: on prête à l'échelle européenne avec la banque centrale ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://julie-sclaunich.emi.u-bordeaux.fr/DATA/API_FR.INR.DPST_DS2_fr_xml_v2_52919.xml'\n",
    "taux = parse_xml_pib(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(144389)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reindex monthly\n",
    "monthly_dates = pd.date_range(start=taux.index.values[0], end=taux.index.values[-1], freq='MS')\n",
    "\n",
    "# Add columns for each month from 2013 to 2023\n",
    "taux = taux.reindex(index=taux.index.union(monthly_dates))\n",
    "\n",
    "# Select only same dates and countries as dette_publique\n",
    "#taux = taux.loc[dette_publique.index, dette_publique.columns.intersection(taux.columns)]\n",
    "\n",
    "def fill_val(x):\n",
    "    \"\"\"Fill missing values by resampling and interpolating.\"\"\"\n",
    "    return x.resample('MS').interpolate(method='quadratic')\n",
    "\n",
    "# Apply the fill_val function to each row\n",
    "taux = taux.apply(func=fill_val, axis=0)\n",
    "\n",
    "taux.isna().sum().sum() # Number of missing values (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Currency</th>\n",
       "      <th>Bosnia and Herzegovina convertible mark</th>\n",
       "      <th>Bulgarian lev</th>\n",
       "      <th>Canadian dollar</th>\n",
       "      <th>Czech koruna</th>\n",
       "      <th>Danish krone</th>\n",
       "      <th>Hungarian forint</th>\n",
       "      <th>Icelandic króna</th>\n",
       "      <th>Japanese yen</th>\n",
       "      <th>North Macedonian denar</th>\n",
       "      <th>Norwegian krone</th>\n",
       "      <th>Polish zloty</th>\n",
       "      <th>Pound sterling</th>\n",
       "      <th>Romanian leu</th>\n",
       "      <th>Russian rouble</th>\n",
       "      <th>Serbian dinar</th>\n",
       "      <th>Swedish krona</th>\n",
       "      <th>Swiss franc</th>\n",
       "      <th>Turkish lira</th>\n",
       "      <th>US dollar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.95583</td>\n",
       "      <td>1.9558</td>\n",
       "      <td>1.368400</td>\n",
       "      <td>25.980000</td>\n",
       "      <td>7.457900</td>\n",
       "      <td>296.870000</td>\n",
       "      <td>162.380000</td>\n",
       "      <td>129.660000</td>\n",
       "      <td>61.585000</td>\n",
       "      <td>7.806700</td>\n",
       "      <td>4.197500</td>\n",
       "      <td>0.849260</td>\n",
       "      <td>4.419000</td>\n",
       "      <td>42.337000</td>\n",
       "      <td>113.136900</td>\n",
       "      <td>8.651500</td>\n",
       "      <td>1.231100</td>\n",
       "      <td>2.533500</td>\n",
       "      <td>1.328100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>1.95583</td>\n",
       "      <td>1.9558</td>\n",
       "      <td>1.384134</td>\n",
       "      <td>26.195389</td>\n",
       "      <td>7.457178</td>\n",
       "      <td>298.365029</td>\n",
       "      <td>161.761335</td>\n",
       "      <td>131.231491</td>\n",
       "      <td>61.590730</td>\n",
       "      <td>7.849537</td>\n",
       "      <td>4.197594</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>4.422440</td>\n",
       "      <td>42.618453</td>\n",
       "      <td>113.521815</td>\n",
       "      <td>8.697162</td>\n",
       "      <td>1.236956</td>\n",
       "      <td>2.577914</td>\n",
       "      <td>1.339790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>1.95583</td>\n",
       "      <td>1.9558</td>\n",
       "      <td>1.397158</td>\n",
       "      <td>26.376653</td>\n",
       "      <td>7.456598</td>\n",
       "      <td>299.637286</td>\n",
       "      <td>161.199346</td>\n",
       "      <td>132.544486</td>\n",
       "      <td>61.595525</td>\n",
       "      <td>7.888816</td>\n",
       "      <td>4.197485</td>\n",
       "      <td>0.847671</td>\n",
       "      <td>4.425333</td>\n",
       "      <td>42.944501</td>\n",
       "      <td>113.864562</td>\n",
       "      <td>8.737177</td>\n",
       "      <td>1.241087</td>\n",
       "      <td>2.615999</td>\n",
       "      <td>1.348489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>1.95583</td>\n",
       "      <td>1.9558</td>\n",
       "      <td>1.410265</td>\n",
       "      <td>26.562635</td>\n",
       "      <td>7.456038</td>\n",
       "      <td>300.959399</td>\n",
       "      <td>160.573608</td>\n",
       "      <td>133.880340</td>\n",
       "      <td>61.600413</td>\n",
       "      <td>7.932953</td>\n",
       "      <td>4.197150</td>\n",
       "      <td>0.846004</td>\n",
       "      <td>4.428299</td>\n",
       "      <td>43.385011</td>\n",
       "      <td>114.238586</td>\n",
       "      <td>8.780119</td>\n",
       "      <td>1.244379</td>\n",
       "      <td>2.655914</td>\n",
       "      <td>1.356062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>1.95583</td>\n",
       "      <td>1.9558</td>\n",
       "      <td>1.421635</td>\n",
       "      <td>26.727907</td>\n",
       "      <td>7.455577</td>\n",
       "      <td>302.152358</td>\n",
       "      <td>159.964517</td>\n",
       "      <td>135.055220</td>\n",
       "      <td>61.604722</td>\n",
       "      <td>7.976317</td>\n",
       "      <td>4.196610</td>\n",
       "      <td>0.843845</td>\n",
       "      <td>4.430932</td>\n",
       "      <td>43.890885</td>\n",
       "      <td>114.595096</td>\n",
       "      <td>8.820316</td>\n",
       "      <td>1.246282</td>\n",
       "      <td>2.692291</td>\n",
       "      <td>1.361329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Currency    Bosnia and Herzegovina convertible mark  Bulgarian lev  \\\n",
       "2013-01-01                                  1.95583         1.9558   \n",
       "2013-02-01                                  1.95583         1.9558   \n",
       "2013-03-01                                  1.95583         1.9558   \n",
       "2013-04-01                                  1.95583         1.9558   \n",
       "2013-05-01                                  1.95583         1.9558   \n",
       "\n",
       "Currency    Canadian dollar  Czech koruna  Danish krone  Hungarian forint  \\\n",
       "2013-01-01         1.368400     25.980000      7.457900        296.870000   \n",
       "2013-02-01         1.384134     26.195389      7.457178        298.365029   \n",
       "2013-03-01         1.397158     26.376653      7.456598        299.637286   \n",
       "2013-04-01         1.410265     26.562635      7.456038        300.959399   \n",
       "2013-05-01         1.421635     26.727907      7.455577        302.152358   \n",
       "\n",
       "Currency    Icelandic króna  Japanese yen  North Macedonian denar  \\\n",
       "2013-01-01       162.380000    129.660000               61.585000   \n",
       "2013-02-01       161.761335    131.231491               61.590730   \n",
       "2013-03-01       161.199346    132.544486               61.595525   \n",
       "2013-04-01       160.573608    133.880340               61.600413   \n",
       "2013-05-01       159.964517    135.055220               61.604722   \n",
       "\n",
       "Currency    Norwegian krone  Polish zloty  Pound sterling  Romanian leu  \\\n",
       "2013-01-01         7.806700      4.197500        0.849260      4.419000   \n",
       "2013-02-01         7.849537      4.197594        0.848684      4.422440   \n",
       "2013-03-01         7.888816      4.197485        0.847671      4.425333   \n",
       "2013-04-01         7.932953      4.197150        0.846004      4.428299   \n",
       "2013-05-01         7.976317      4.196610        0.843845      4.430932   \n",
       "\n",
       "Currency    Russian rouble  Serbian dinar  Swedish krona  Swiss franc  \\\n",
       "2013-01-01       42.337000     113.136900       8.651500     1.231100   \n",
       "2013-02-01       42.618453     113.521815       8.697162     1.236956   \n",
       "2013-03-01       42.944501     113.864562       8.737177     1.241087   \n",
       "2013-04-01       43.385011     114.238586       8.780119     1.244379   \n",
       "2013-05-01       43.890885     114.595096       8.820316     1.246282   \n",
       "\n",
       "Currency    Turkish lira  US dollar  \n",
       "2013-01-01      2.533500   1.328100  \n",
       "2013-02-01      2.577914   1.339790  \n",
       "2013-03-01      2.615999   1.348489  \n",
       "2013-04-01      2.655914   1.356062  \n",
       "2013-05-01      2.692291   1.361329  "
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL of the CSV file\n",
    "url_3 = 'https://julie-sclaunich.emi.u-bordeaux.fr/DATA/estat_tec00033_filtered_en.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "devise = pd.read_csv(url_3)\n",
    "\n",
    "# Remove unnecessary columns to clean up the data\n",
    "columns_to_delete = ['DATAFLOW', 'LAST UPDATE', 'freq', 'statinfo', 'unit', 'OBS_FLAG']\n",
    "devise.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "# Convert 'TIME_PERIOD' to datetime format and filter rows after 2012\n",
    "devise['TIME_PERIOD'] = pd.to_datetime(devise['TIME_PERIOD'], format='%Y', errors='coerce')  # Convert to datetime\n",
    "devise = devise[devise['TIME_PERIOD'] > '2012-12-31']  # Keep rows with dates after 2012\n",
    "devise['TIME_PERIOD'] = devise['TIME_PERIOD'].dt.strftime('%Y/%m')  # Format as YYYY/MM\n",
    "\n",
    "# Reshape the DataFrame to have 'TIME_PERIOD' as row index and 'currency' as columns\n",
    "devise = devise.pivot(index='TIME_PERIOD', columns='currency', values='OBS_VALUE')\n",
    "\n",
    "# Set the index to be a DatetimeIndex for resampling\n",
    "devise.index = pd.to_datetime(devise.index, format='%Y/%m', errors='coerce')\n",
    "devise.index.name = None\n",
    "devise.columns.name = 'Currency'\n",
    "\n",
    "# Define a function to fill missing values by resampling and interpolating\n",
    "def fill_val(x):\n",
    "    \"\"\"Fill missing values by resampling to monthly frequency and using quadratic interpolation.\"\"\"\n",
    "    return x.resample('MS').interpolate(method='quadratic')\n",
    "\n",
    "# Apply the interpolation function to fill missing values\n",
    "devise = fill_val(devise)\n",
    "print(devise.isna().sum().sum()) # Number of missing values (24 a voir pourquoi)\n",
    "# Display a sample of the corrected data\n",
    "devise.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matières premières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>201.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>198.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>195.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>190.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Or\n",
       "2023-12-01  201.5\n",
       "2023-11-01  198.6\n",
       "2023-10-01  195.8\n",
       "2023-09-01  194.0\n",
       "2023-08-01  190.2"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_or = \"https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/010002100\" # URL of the serie\n",
    "\n",
    "response = requests.get(url_or) # Retrieve XML data\n",
    "response.raise_for_status() # Checks that the request is successful\n",
    "xml_content = response.content\n",
    "\n",
    "\n",
    "root = ET.fromstring(xml_content) # Parse XML content\n",
    "\n",
    "root = ET.fromstring(xml_content) # Load XML content\n",
    "\n",
    "\n",
    "data = [] # Initialize a list to store the data\n",
    "\n",
    "\n",
    "for series in root.findall(\".//{*}Series\"): # Browse each series\n",
    "\n",
    "    for obs in series.findall(\".//{*}Obs\"): # Browse the observation in  each series\n",
    "\n",
    "        # Extract relevant \n",
    "        time_period = obs.attrib.get(\"TIME_PERIOD\")\n",
    "        obs_value = obs.attrib.get(\"OBS_VALUE\")\n",
    "        # Add the data at the list\n",
    "        data.append({\"TIME_PERIOD\": time_period, \"OBS_VALUE\": obs_value})\n",
    "\n",
    "\n",
    "df_or = pd.DataFrame(data) # Create a DataFrame from the extracted data\n",
    "\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "df_or[\"TIME_PERIOD\"] = pd.to_datetime(df_or[\"TIME_PERIOD\"], format=\"%Y-%m\")\n",
    "df_or[\"OBS_VALUE\"] = pd.to_numeric(df_or[\"OBS_VALUE\"])\n",
    "\n",
    "\n",
    "\n",
    "# Convert TIME_PERIOD to datetime for easier filtering\n",
    "df_or['TIME_PERIOD'] = pd.to_datetime(df_or['TIME_PERIOD'], format='%Y-%m')\n",
    "\n",
    "# Filter years between 2013 and 2023\n",
    "start_date = '2013-01-01'\n",
    "end_date = '2023-12-31'\n",
    "df_or = df_or[(df_or['TIME_PERIOD'] >= start_date) & (df_or['TIME_PERIOD'] <= end_date)]\n",
    "\n",
    "df_or.set_index('TIME_PERIOD', inplace=True) #indexes the years\n",
    "df_or.index.name = None\n",
    "df_or.columns.name = None\n",
    "df_or.rename(columns = {'OBS_VALUE': 'Or'}, inplace = True)\n",
    "print(df_or.isna().sum().sum()) # Number of missing values (0)\n",
    "# show the 5 first rows\n",
    "df_or.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Material</th>\n",
       "      <th>Petrol</th>\n",
       "      <th>Or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>118.1</td>\n",
       "      <td>201.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>127.3</td>\n",
       "      <td>198.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>142.3</td>\n",
       "      <td>195.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>145.2</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>130.9</td>\n",
       "      <td>190.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Material    Petrol     Or\n",
       "2023-12-01   118.1  201.5\n",
       "2023-11-01   127.3  198.6\n",
       "2023-10-01   142.3  195.8\n",
       "2023-09-01   145.2  194.0\n",
       "2023-08-01   130.9  190.2"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_petrol = \"https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/010002091\" # URL of the serie\n",
    "\n",
    "response = requests.get(url_petrol) # Retrieve XML data\n",
    "response.raise_for_status()   # Checks that the request is successful\n",
    "xml_content = response.content\n",
    "\n",
    "\n",
    "root = ET.fromstring(xml_content) # Parse XML content\n",
    "\n",
    "root = ET.fromstring(xml_content) # Load XML content\n",
    "\n",
    "# Initialiser une liste pour stocker les données\n",
    "data = []\n",
    "\n",
    "\n",
    "for series in root.findall(\".//{*}Series\"): # Browse each series\n",
    "   \n",
    "    for obs in series.findall(\".//{*}Obs\"):  # Browse the observation in  each series\n",
    "\n",
    "       # Extract relevant attributes\n",
    "        time_period = obs.attrib.get(\"TIME_PERIOD\")\n",
    "        obs_value = obs.attrib.get(\"OBS_VALUE\")\n",
    "         # Add the data at the list\n",
    "        data.append({\"TIME_PERIOD\": time_period, \"OBS_VALUE\": obs_value})\n",
    "\n",
    "\n",
    "df_petrol = pd.DataFrame(data)  # Create a DataFrame from the extracted data\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "df_petrol[\"TIME_PERIOD\"] = pd.to_datetime(df_petrol[\"TIME_PERIOD\"], format=\"%Y-%m\")\n",
    "df_petrol[\"OBS_VALUE\"] = pd.to_numeric(df_petrol[\"OBS_VALUE\"])\n",
    "\n",
    "\n",
    "# Convert TIME_PERIOD to datetime for easier filtering\n",
    "df_petrol['TIME_PERIOD'] = pd.to_datetime(df_petrol['TIME_PERIOD'], format='%Y-%m')\n",
    "\n",
    "# Filter years between 2013 and 2023\n",
    "start_date = '2013-01-01'\n",
    "end_date = '2023-12-31'\n",
    "df_petrol = df_petrol[(df_petrol['TIME_PERIOD'] >= start_date) & (df_petrol['TIME_PERIOD'] <= end_date)]\n",
    "\n",
    "df_petrol.set_index('TIME_PERIOD', inplace=True) #indexes the years\n",
    "df_petrol.index.name = None\n",
    "df_petrol.columns.name = None\n",
    "df_petrol.rename(columns = {'OBS_VALUE': 'Petrol'}, inplace = True)\n",
    "\n",
    "print(ipch.isna().sum().sum()) # Number of missing values (0)\n",
    "# show the 5 first rows\n",
    "df_petrol.head()\n",
    "material = pd.concat((df_petrol, df_or), axis = 1, join = 'inner')\n",
    "material.columns.name = 'Material'\n",
    "material.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion des dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les dates du 01/01/2023       au 01/01/2013 sont présentes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/8spvhwwd3gjgp2cl9zvhb_4m0000gn/T/ipykernel_32258/126585854.py:36: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  data = data.groupby('Type', axis = 1)\n"
     ]
    }
   ],
   "source": [
    "common_countries = ipch.columns.intersection(\\\n",
    "                   dette_publique.columns.intersection(\\\n",
    "                   chomage.columns.intersection(\\\n",
    "                    pib.columns)))\n",
    "\n",
    "common_dates = ipch.index.intersection(\\\n",
    "                   dette_publique.index.intersection(\\\n",
    "                   chomage.index.intersection(\\\n",
    "                    pib.index)))\n",
    "\n",
    "expected_dates = pd.date_range(start='2013-01-01', end='2023-01-01', freq='MS')\n",
    "all_dates_present = expected_dates.isin(common_dates).all()\n",
    "\n",
    "print(f'Toutes les dates du {common_dates[-1].strftime('%d/%m/%Y')}\\\n",
    "       au {common_dates[0].strftime('%d/%m/%Y')} sont présentes' \\\n",
    "        if all_dates_present else 'Il manque des dates')\n",
    "\n",
    "def set_index(df, index_name):\n",
    "    df = df.loc[common_dates, common_countries]\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # Ajouter le nouvel index au niveau supérieur du MultiIndex existant\n",
    "        new_index = pd.MultiIndex.from_tuples([(index_name, *idx) \\\n",
    "                        for idx in df.columns], names=['Type'] + df.columns.names)\n",
    "    else:\n",
    "        # Créer un MultiIndex en juxtaposant le nouvel index et l'index existant\n",
    "        new_index = pd.MultiIndex.from_tuples([(index_name, idx) \n",
    "                        for idx in df.columns], names=['Type', df.columns.names[0]])\n",
    "    df.columns = new_index\n",
    "    return df\n",
    "dette_publique = set_index(dette_publique, 'Dette publique')\n",
    "chomage = set_index(chomage, 'Chomage')\n",
    "ipch = set_index(ipch, 'IPCH')\n",
    "pib = set_index(pib, 'PIB')\n",
    "\n",
    "data = pd.concat((dette_publique, chomage, ipch, pib), axis = 1, join = 'inner')\n",
    "data = data.groupby('Type', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th colspan=\"21\" halign=\"left\">IPCH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Autriche</th>\n",
       "      <th>Belgique</th>\n",
       "      <th>Bulgarie</th>\n",
       "      <th>Chypre</th>\n",
       "      <th>Allemagne</th>\n",
       "      <th>Danemark</th>\n",
       "      <th>Estonie</th>\n",
       "      <th>Grèce</th>\n",
       "      <th>Espagne</th>\n",
       "      <th>Finlande</th>\n",
       "      <th>...</th>\n",
       "      <th>Lituanie</th>\n",
       "      <th>Luxembourg</th>\n",
       "      <th>Lettonie</th>\n",
       "      <th>Malte</th>\n",
       "      <th>Pays-Bas</th>\n",
       "      <th>Pologne</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Roumanie</th>\n",
       "      <th>Suède</th>\n",
       "      <th>Slovénie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>11.6</td>\n",
       "      <td>13.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>13.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>11.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>14.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>10.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>11.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>18.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Type           IPCH                                                            \\\n",
       "Country    Autriche Belgique Bulgarie Chypre Allemagne Danemark Estonie Grèce   \n",
       "2013-01-01      2.8      1.5      2.6    2.0       1.9      0.9     3.7   0.0   \n",
       "2013-02-01      2.6      1.5      2.2    1.8       1.8      1.1     4.0   0.1   \n",
       "2013-03-01      2.4      1.4      1.6    1.3       1.9      0.7     3.8  -0.2   \n",
       "2013-04-01      2.1      1.2      0.9    0.1       1.1      0.5     3.4  -0.6   \n",
       "2013-05-01      2.4      1.2      1.0    0.1       1.5      0.7     3.6  -0.3   \n",
       "...             ...      ...      ...    ...       ...      ...     ...   ...   \n",
       "2022-09-01     11.0     12.1     15.6    9.0      10.9     11.1    24.1  12.1   \n",
       "2022-10-01     11.6     13.1     14.8    8.6      11.6     11.4    22.5   9.5   \n",
       "2022-11-01     11.2     10.5     14.3    8.1      11.3      9.7    21.4   8.8   \n",
       "2022-12-01     10.5     10.2     14.3    7.6       9.6      9.6    17.5   7.6   \n",
       "2023-01-01     11.6      7.4     14.3    6.8       9.2      8.4    18.6   7.3   \n",
       "\n",
       "Type                         ...                                              \\\n",
       "Country    Espagne Finlande  ... Lituanie Luxembourg Lettonie Malte Pays-Bas   \n",
       "2013-01-01     2.8      2.6  ...      2.7        2.1      0.6   2.4      3.2   \n",
       "2013-02-01     2.9      2.4  ...      2.3        2.4      0.3   1.8      3.2   \n",
       "2013-03-01     2.6      2.5  ...      1.6        2.0      0.3   1.4      3.2   \n",
       "2013-04-01     1.5      2.4  ...      1.4        1.7     -0.4   0.9      2.8   \n",
       "2013-05-01     1.8      2.5  ...      1.5        1.4     -0.2   0.8      3.1   \n",
       "...            ...      ...  ...      ...        ...      ...   ...      ...   \n",
       "2022-09-01     9.0      8.4  ...     22.5        8.8     22.0   7.4     17.1   \n",
       "2022-10-01     7.3      8.4  ...     22.1        8.8     21.7   7.4     16.8   \n",
       "2022-11-01     6.7      9.1  ...     21.4        7.3     21.7   7.2     11.3   \n",
       "2022-12-01     5.5      8.8  ...     20.0        6.2     20.7   7.3     11.0   \n",
       "2023-01-01     5.9      7.9  ...     18.5        5.8     21.4   6.8      8.4   \n",
       "\n",
       "Type                                                 \n",
       "Country    Pologne Portugal Roumanie Suède Slovénie  \n",
       "2013-01-01     1.6      0.4      5.1   0.6      2.8  \n",
       "2013-02-01     1.2      0.2      4.9   0.5      2.9  \n",
       "2013-03-01     1.0      0.7      4.4   0.5      2.2  \n",
       "2013-04-01     0.8      0.4      4.4   0.0      1.6  \n",
       "2013-05-01     0.5      0.9      4.4   0.3      1.6  \n",
       "...            ...      ...      ...   ...      ...  \n",
       "2022-09-01    15.7      9.8     13.4  10.3     10.6  \n",
       "2022-10-01    16.4     10.6     13.5   9.8     10.3  \n",
       "2022-11-01    16.1     10.2     14.6  10.1     10.8  \n",
       "2022-12-01    15.3      9.8     14.1  10.8     10.8  \n",
       "2023-01-01    15.9      8.6     13.4   9.6      9.9  \n",
       "\n",
       "[121 rows x 25 columns]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_group('IPCH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage\n",
    "\n",
    "L'affichage des graphiques se fait trois fois, je ne sais pas pourquoi.\\\n",
    "Pour l'affichage de la carte, j'ai commencé à coder une fonction tout en bas. Il manque la traduction des noms des pays. Je ne sais pas si ça va fonctionner après ça, à voir.\n",
    "\n",
    "## Fonction d'affichage de graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(countries, start, end, data, data_type):\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    for country in countries.split(', '):\n",
    "        data.loc[start:end, (data_type, country)].plot(label=f'{country}')\n",
    "\n",
    "    plt.title(f'{data_type} ({start.strftime(\"%m/%Y\")} - {end.strftime(\"%m/%Y\")})')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'affichage de carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON file into a GeoDataFrame\n",
    "url = \"https://raw.githubusercontent.com/leakyMirror/map-of-europe/master/GeoJSON/europe.geojson\"\n",
    "europe = gpd.read_file(url)\n",
    "\n",
    "def plot_map(date: str, data: pd.core.groupby.DataFrameGroupBy, data_type: str):\n",
    "    \"\"\"\n",
    "    Plot a map of Europe for the specified date and data type.\n",
    "    \n",
    "    Args:\n",
    "        date (str): Date in 'YYYY-MM' format for which to filter the data.\n",
    "        data (pd.core.groupby.DataFrameGroupBy): A grouped DataFrame with MultiIndex columns\n",
    "            ('Type', 'Country') and a DateTimeIndex.\n",
    "        data_type (str): The type of data to display (e.g., 'IPCH').\n",
    "    \"\"\"\n",
    "    # Prepare the data\n",
    "    df = data.get_group(data_type).copy()\n",
    "    df.columns = df.columns.droplevel('Type')\n",
    "    df.rename(columns={\n",
    "        \"Albanie\": \"Albania\",\n",
    "        \"Allemagne\": \"Germany\",\n",
    "        \"Andorre\": \"Andorra\",\n",
    "        \"Autriche\": \"Austria\",\n",
    "        \"Belgique\": \"Belgium\",\n",
    "        \"Biélorussie\": \"Belarus\",\n",
    "        \"Bosnie-Herzégovine\": \"Bosnia and Herzegovina\",\n",
    "        \"Bulgarie\": \"Bulgaria\",\n",
    "        \"Croatie\": \"Croatia\",\n",
    "        \"Danemark\": \"Denmark\",\n",
    "        \"Espagne\": \"Spain\",\n",
    "        \"Estonie\": \"Estonia\",\n",
    "        \"Finlande\": \"Finland\",\n",
    "        \"France\": \"France\",\n",
    "        \"Grèce\": \"Greece\",\n",
    "        \"Hongrie\": \"Hungary\",\n",
    "        \"Irlande\": \"Ireland\",\n",
    "        \"Islande\": \"Iceland\",\n",
    "        \"Italie\": \"Italy\",\n",
    "        \"Kosovo\": \"Kosovo\",\n",
    "        \"Lettonie\": \"Latvia\",\n",
    "        \"Liechtenstein\": \"Liechtenstein\",\n",
    "        \"Lituanie\": \"Lithuania\",\n",
    "        \"Luxembourg\": \"Luxembourg\",\n",
    "        \"Malte\": \"Malta\",\n",
    "        \"Moldavie\": \"Moldova\",\n",
    "        \"Monaco\": \"Monaco\",\n",
    "        \"Monténégro\": \"Montenegro\",\n",
    "        \"Norvège\": \"Norway\",\n",
    "        \"Pays-Bas\": \"Netherlands\",\n",
    "        \"Pologne\": \"Poland\",\n",
    "        \"Portugal\": \"Portugal\",\n",
    "        \"République tchèque\": \"Czech Republic\",\n",
    "        \"Roumanie\": \"Romania\",\n",
    "        \"Royaume-Uni\": \"United Kingdom\",\n",
    "        \"Russie\": \"Russia\",\n",
    "        \"Saint-Marin\": \"San Marino\",\n",
    "        \"Serbie\": \"Serbia\",\n",
    "        \"Slovaquie\": \"Slovakia\",\n",
    "        \"Slovénie\": \"Slovenia\",\n",
    "        \"Suède\": \"Sweden\",\n",
    "        \"Suisse\": \"Switzerland\",\n",
    "        \"Ukraine\": \"Ukraine\",\n",
    "        \"Vatican\": \"Vatican City\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    df.index.name = None\n",
    "    df.columns.name = 'Material'\n",
    "\n",
    "    # Melt the DataFrame to long format for merging\n",
    "    df_melted = df.reset_index().melt(id_vars='index', var_name='Country', value_name='Value')\n",
    "    df_melted.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "    # Merge GeoJSON data with DataFrame\n",
    "    europe_merged = europe.merge(df_melted, left_on='NAME', right_on='Country', how='left')\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    europe_merged.plot(column='Value', ax=ax, legend=True, cmap='viridis', \n",
    "                       missing_kwds={\"color\": \"lightgrey\"},\n",
    "                       legend_kwds={'label': data_type})\n",
    "\n",
    "    plt.title(f\"Map of {data_type} in Europe in {pd.to_datetime(date).strftime('%B %Y')}\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63760b991001476daac19133f3e2b4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='France, Allemagne, Italie', continuous_update=False, description='Countries:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets pour sélectionner les pays et les dates\n",
    "countries_widget = widgets.Text(\n",
    "    value='France, Allemagne, Italie',\n",
    "    description='Countries:',\n",
    "    placeholder='Enter countries separated by commas'\n",
    ")\n",
    "\n",
    "start_date_widget = widgets.DatePicker(\n",
    "    value=pd.to_datetime('2015-1', format='%Y-%m'),\n",
    "    description='Start Date'\n",
    ")\n",
    "\n",
    "end_date_widget = widgets.DatePicker(\n",
    "    value=pd.to_datetime('2020-3', format='%Y-%m'),\n",
    "    description='End Date'\n",
    ")\n",
    "\n",
    "# Widget pour choix multiple des données à afficher\n",
    "multi_choice_widget = widgets.SelectMultiple(\n",
    "    options=['IPCH', 'Dette publique', 'PIB', 'Chomage'],\n",
    "    value=['IPCH'],\n",
    "    description='Select Data',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Widget case à cocher\n",
    "checkbox_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Map',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Fonction générale pour tracer les données\n",
    "@interact_manual(countries=countries_widget, \\\n",
    "                 start_date=start_date_widget, end_date=end_date_widget, \\\n",
    "                 type=multi_choice_widget, map=checkbox_widget)\n",
    "def plot_G(countries, start_date, end_date, type, map = True):\n",
    "    if map:\n",
    "        plot_map(date = start_date, data = data, data_type= type[0])\n",
    "    else:\n",
    "        for t in type:\n",
    "            plot_graph(countries, start_date, end_date, data.get_group(t), t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/local/stow/conda/miniforge3/envs/cremi/share/proj failed\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Not allowed to merge between different levels. (1 levels on the left, 2 on the right)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mplot_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPIB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPIB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mplot_map\u001b[0;34m(year, data, data_type)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_map\u001b[39m(year, data, data_type):\n\u001b[1;32m      9\u001b[0m     to_plot \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-01\u001b[39m\u001b[38;5;124m'\u001b[39m, :]\n\u001b[0;32m---> 10\u001b[0m     to_plot \u001b[38;5;241m=\u001b[39m \u001b[43meurope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     13\u001b[0m     europe\u001b[38;5;241m.\u001b[39mplot(ax\u001b[38;5;241m=\u001b[39max, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgrey\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/local/stow/conda/miniforge3/envs/cremi/lib/python3.12/site-packages/pandas/core/frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/stow/conda/miniforge3/envs/cremi/lib/python3.12/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/local/stow/conda/miniforge3/envs/cremi/lib/python3.12/site-packages/pandas/core/reshape/merge.py:784\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m!=\u001b[39m _right\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m    779\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot allowed to merge between different levels. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m levels on the left, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on the right)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    783\u001b[0m     )\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_on, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_left_right_on(left_on, right_on)\n\u001b[1;32m    788\u001b[0m (\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     right_drop,\n\u001b[1;32m    794\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n",
      "\u001b[0;31mMergeError\u001b[0m: Not allowed to merge between different levels. (1 levels on the left, 2 on the right)"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/leakyMirror/map-of-europe/master/GeoJSON/europe.geojson\"\n",
    "europe = gpd.read_file(url)\n",
    "\n",
    "def plot_map(year, data, data_type):\n",
    "    to_plot = data.loc[f'{year}-01', :]\n",
    "    to_plot = europe.merge(to_plot, left_on='NAME', right_index=True, how='left')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    europe.plot(ax=ax, color='lightgrey', edgecolor='black')\n",
    "    to_plot.plot(column='Value', ax=ax, legend=True, cmap='viridis', \n",
    "                 missing_kwds={\"color\": \"lightgrey\", \"label\": \"Données manquantes\"},\n",
    "                 legend_kwds={'label': \"PIB\", 'orientation': \"vertical\"},\n",
    "                 edgecolor='black')\n",
    "    \n",
    "    ax.set_title(f\"Carte des PIB en Europe (en {year})\", fontsize=16)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_map(2020, data.get_group('PIB'), 'PIB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage matières premières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996bd722dc2d426bb2a5a67ad70bea39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=Timestamp('2013-01-01 00:00:00'), description='Début', step=1), DatePic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_data(start_date, end_date, show_or, show_petrol)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Function to plot the data\n",
    "def plot_data(start_date, end_date, show_or, show_petrol):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    start_date, end_date = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "    \n",
    "    # Filter the data based on the selected dates\n",
    "    filtered_material = material[(material.index >= start_date) & (material.index <= end_date)]\n",
    "    \n",
    "    if show_or:\n",
    "        sb.lineplot(data=filtered_material, x=filtered_material.index, y='Or', label='Or', marker='o')\n",
    "        # If 'Or' checkbox is checked, plot the data for 'Or'\n",
    "\n",
    "    if show_petrol:\n",
    "        sb.lineplot(data=filtered_material, x=filtered_material.index, y='Petrol', label='Pétrole', marker='o')\n",
    "        # If 'Petrol' checkbox is checked, plot the data for 'Petrol'\n",
    "\n",
    "    # Configure the plot with a title, legend, and grid\n",
    "    plt.title(f'Cour de l\\'or et du pétrole en euros ({start_date.strftime(\"%m/%Y\")} - {end_date.strftime(\"%m/%Y\")})')\n",
    "    plt.legend()  # The legend is automatically updated based on the checked datasets\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Widgets for selecting the start and end dates, and options to display data\n",
    "start_date_widget = widgets.DatePicker(description='Début', value=pd.to_datetime('2013-01-01'))\n",
    "end_date_widget = widgets.DatePicker(description='Fin', value=pd.to_datetime('2023-12-31'))\n",
    "show_or_widget = widgets.Checkbox(description='Or', value=True)  # Checkbox for showing 'Or' data\n",
    "show_petrol_widget = widgets.Checkbox(description='Pétrole', value=True)  # Checkbox for showing 'Petrol' data\n",
    "\n",
    "# Interactive interface to control the plot function with widgets\n",
    "interact(\n",
    "    plot_data,  # The function to interact with\n",
    "    start_date=start_date_widget,  # Start date widget\n",
    "    end_date=end_date_widget,  # End date widget\n",
    "    show_or=show_or_widget,  # 'Or' checkbox widget\n",
    "    show_petrol=show_petrol_widget  # 'Petrol' checkbox widget\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des devises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7887f47f8aa4a50b5ae8c100d9151f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='Tout sélectionner'), DatePicker(value=Timestamp('2013…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_devise_data(select_all, start_date, end_date, **currency_checkboxes)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to plot currency data\n",
    "def plot_devise_data(select_all, start_date, end_date, **currency_checkboxes):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # List of selected currencies\n",
    "    if select_all:\n",
    "        selected_currencies = devise.columns.tolist()  # If \"select all\" is checked, include all currencies\n",
    "    else:\n",
    "        selected_currencies = [currency for currency, is_selected in currency_checkboxes.items() if is_selected]\n",
    "        # If not, include only the selected currencies based on the checkboxes\n",
    "\n",
    "    # Filter the data based on the selected date range and currencies\n",
    "    filtered_data = devise[(devise.index >= start_date) & (devise.index <= end_date)]\n",
    "    filtered_data = filtered_data[selected_currencies]\n",
    "\n",
    "    # Plot the time series for each selected currency\n",
    "    for currency in selected_currencies:\n",
    "        sb.lineplot(data=filtered_data, x=filtered_data.index, y=currency, label=currency, marker='o')\n",
    "\n",
    "    # Configure the plot with a title, x and y labels, and a legend\n",
    "    plt.title(f'Valeurs des devises (équivalent en euros) ({start_date.strftime(\"%m/%Y\")} - {end_date.strftime(\"%m/%Y\")})')\n",
    "    plt.xlabel('TIME_PERIOD')\n",
    "    plt.ylabel('OBS_VALUE')\n",
    "    plt.legend(title='Currency')  # Currency legend\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Widgets for selecting the start and end dates\n",
    "start_date_widget = widgets.DatePicker(description='Début', value=pd.to_datetime('2013-01-01'))\n",
    "end_date_widget = widgets.DatePicker(description='Fin', value=pd.to_datetime('2023-12-31'))\n",
    "\n",
    "# Dynamically generate checkboxes for each currency\n",
    "currency_checkboxes = {\n",
    "    currency: widgets.Checkbox(description=currency, value=False)  # Default value is False (unchecked)\n",
    "    for currency in devise.columns\n",
    "}\n",
    "\n",
    "# Checkbox to \"Select All\" currencies\n",
    "select_all_widget = widgets.Checkbox(description='Tout sélectionner', value=False)\n",
    "\n",
    "# Function to dynamically update checkboxes based on \"Select All\"\n",
    "def update_checkboxes(change):\n",
    "    for checkbox in currency_checkboxes.values():\n",
    "        checkbox.value = change['new']  # Update the state of checkboxes based on the \"Select All\" checkbox\n",
    "\n",
    "select_all_widget.observe(update_checkboxes, names='value')  # Observe changes to the \"Select All\" checkbox\n",
    "\n",
    "# Create a container for all the checkboxes\n",
    "checkbox_container = VBox([select_all_widget] + list(currency_checkboxes.values()))\n",
    "\n",
    "# Interactive interface to control the plot function with widgets\n",
    "interact(\n",
    "    plot_devise_data,  # The function to interact with\n",
    "    select_all=select_all_widget,  # \"Select All\" widget\n",
    "    start_date=start_date_widget,  # Start date widget\n",
    "    end_date=end_date_widget,  # End date widget\n",
    "    **currency_checkboxes  # Pass each currency checkbox widget as a parameter\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 PIB                                                    \\\n",
      "Country         Autriche  Belgique  Bulgarie    Chypre Allemagne  Danemark   \n",
      "Type Country                                                                 \n",
      "PIB  Autriche   1.000000  0.990586  0.906579  0.962533  0.993234  0.963908   \n",
      "     Belgique   0.990586  1.000000  0.930290  0.973268  0.979347  0.981178   \n",
      "     Bulgarie   0.906579  0.930290  1.000000  0.983123  0.880897  0.925532   \n",
      "     Chypre     0.962533  0.973268  0.983123  1.000000  0.942629  0.962962   \n",
      "     Allemagne  0.993234  0.979347  0.880897  0.942629  1.000000  0.963257   \n",
      "\n",
      "Type                                                    ...      IPCH  \\\n",
      "Country          Estonie     Grèce   Espagne  Finlande  ...  Lituanie   \n",
      "Type Country                                            ...             \n",
      "PIB  Autriche   0.938519  0.637396  0.958764  0.962428  ...  0.649532   \n",
      "     Belgique   0.945167  0.656340  0.939378  0.948630  ...  0.685807   \n",
      "     Bulgarie   0.988240  0.388354  0.819593  0.797372  ...  0.776166   \n",
      "     Chypre     0.990660  0.492993  0.892280  0.882768  ...  0.727528   \n",
      "     Allemagne  0.921830  0.616938  0.936946  0.978944  ...  0.576721   \n",
      "\n",
      "Type                                                                         \\\n",
      "Country        Luxembourg  Lettonie     Malte  Pays-Bas   Pologne  Portugal   \n",
      "Type Country                                                                  \n",
      "PIB  Autriche    0.649376  0.587124  0.483208  0.635156  0.769894  0.523888   \n",
      "     Belgique    0.684618  0.621437  0.514694  0.678838  0.814145  0.557605   \n",
      "     Bulgarie    0.732925  0.724778  0.618549  0.741145  0.897544  0.653624   \n",
      "     Chypre      0.712580  0.666345  0.560293  0.706104  0.851151  0.597249   \n",
      "     Allemagne   0.573872  0.514082  0.403540  0.564351  0.720011  0.446874   \n",
      "\n",
      "Type                                          \n",
      "Country         Roumanie     Suède  Slovénie  \n",
      "Type Country                                  \n",
      "PIB  Autriche   0.743113  0.632781  0.637924  \n",
      "     Belgique   0.771293  0.661347  0.668158  \n",
      "     Bulgarie   0.795084  0.772618  0.706029  \n",
      "     Chypre     0.786932  0.718094  0.682381  \n",
      "     Allemagne  0.679405  0.561292  0.564102  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "def correlation_matrix(data, variables):\n",
    "  \"\"\"Return the correlation matrix for specified variables.\"\"\"\n",
    "  data_flat = data.apply(lambda x: x.droplevel(0, axis=1))  # Flatten MultiIndex\n",
    "  return data_flat[variables].corr()  # Compute and return correlation matrix\n",
    "\n",
    "#test\n",
    "variables = ['PIB', 'Chomage','IPCH']\n",
    "print(correlation_matrix(data, variables).head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
